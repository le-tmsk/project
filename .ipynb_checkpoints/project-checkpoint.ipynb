{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SWIMPLACES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#how to access another than the first page\n",
    "response = requests.get('https://www.mapotic.com/api/v1/maps/2941/public-pois/?page=1&page_size=10&ordering=created&page=4')\n",
    "print(response)\n",
    "#response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swim():\n",
    "    '''\n",
    "    This Class will be used to download all data and merge them into one DataFrame.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.pages_json = self.downloadPages()\n",
    "        self.get_data = self.getData()\n",
    "        pass\n",
    "    def downloadPages(self):\n",
    "        \"\"\"Download data from API and save to a json file.\"\"\"\n",
    "        \n",
    "        resp=[]\n",
    "        b= tqdm([1,2], desc=\"Downloading JSON data from API\")  # MAZU 2 STRANKY PRO RYCHLOST a mensim page_size z 1000 na 50!!\n",
    "        for i in b:\n",
    "            response = requests.get('https://www.mapotic.com/api/v1/maps/2941/public-pois/?page=1&page_size=20&ordering=created&page='+ str(i) )\n",
    "            resp.append(response.json())\n",
    "#         with open('raw_data.json', 'w') as raw:   # uložit do classy, ale aby se to pokaždé nestahovalo... plus podmínku, kdy se má stáhnout\n",
    "#             json.dump(resp, raw) \n",
    "        return resp\n",
    "            \n",
    "    def getData(self):\n",
    "        \"\"\"Extract available data from JSON\"\"\"\n",
    "        preview = self.pages_json\n",
    "#         with open('raw_data.json') as raw_data: \n",
    "#             preview = json.load(raw_data)\n",
    "        latitude = []    \n",
    "        longitude = []\n",
    "        ids = [] \n",
    "        names = [] \n",
    "#         types =[]\n",
    "        ratings = []\n",
    "        count_ratings = []\n",
    "        created = []\n",
    "        coordinates = []\n",
    "        for page in preview: \n",
    "            for result in page['results']:\n",
    "                names.append(result['name'])\n",
    "                ids.append(result['id'])\n",
    "                latitude.append(result['point']['coordinates'][0])\n",
    "                longitude.append(result['point']['coordinates'][1])\n",
    "#                 types.append(result['category']['name']['en'][0])  #z nějakého důvodu nefunguje - NoneType error\n",
    "                ratings.append(result['rating']['average'])\n",
    "                count_ratings.append(result['rating']['count'])\n",
    "                created.append(result['created'])\n",
    "                coordinates.append(result['point']['coordinates'])\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'ID' : ids, \n",
    "            'Name' : names, \n",
    "#             'type' : types,\n",
    "            'Average rating' : ratings,\n",
    "            'Number of ratings' : count_ratings,\n",
    "            'Created' : created,\n",
    "            'Longitude' : longitude,\n",
    "            'Latitude' : latitude})\n",
    "#         return df \n",
    "        return df.loc[:30]  #zde ukáže momentálně pár záznamů, jen pro kontrolu\n",
    "    \n",
    "    def getDescPlaces(self, idn, name):\n",
    "        \"\"\"Function to get the source (only the part we are interested in) from each specific website. ID and name (without diacritics) have to be entered.\"\"\"\n",
    "        \n",
    "        name = unicodedata.normalize('NFKD', name).lower()\n",
    "        new_name = ''\n",
    "        for c in name:\n",
    "            if not unicodedata.combining(c):\n",
    "                new_name += c\n",
    "                \n",
    "        odkaz = 'https://www.swimplaces.com/'  + str(idn) + '-'+ new_name.replace(' ', '-') \n",
    "        r = requests.get(odkaz)\n",
    "        r.encoding = 'UTF-8'\n",
    "        soup = BeautifulSoup(r.text,'lxml').find('meta', {'name' : 'description'})['content'].split('|')\n",
    "        return soup\n",
    "    \n",
    "    def getAtt(self):\n",
    "        \"\"\"Download attributes for all the places.\"\"\"\n",
    "        value = None\n",
    "        def find_between(string, start, end):  #pomocná na hledání ve stringu\n",
    "            return (string.split(start))[1].split(end)[0]\n",
    "        \n",
    "        nazev =[]\n",
    "        att = []\n",
    "        for i, n in self.get_data.iterrows(): #self.getData().iterrows(): \n",
    "            nazev.append(self.getDescPlaces(n['ID'], n['Name'])[0])\n",
    "            try:\n",
    "                att.append(self.getDescPlaces(n['ID'], n['Name'])[1])  # tady už to někdy hodilo chybu, ze to nenašlo...\n",
    "            except:\n",
    "                att.append(value)\n",
    "        ids_att = self.get_data['ID'].values #self.getData()['ID'].values #přidat ID, pro pozdější join\n",
    "        \n",
    "        desc = []\n",
    "        refresh = []\n",
    "        diving = []\n",
    "        entrances = []\n",
    "        access = []\n",
    "        nudists = []\n",
    "        for ii in tqdm(att, desc = 'Searching through the description for attributes:'): # tady zkusim pridat taky tqdm\n",
    "            if 'Description:' in ii:\n",
    "                desc.append(find_between(ii, 'Description:', ':').rsplit(' ', 1)[0].rsplit(',', 1)[0].strip()) # najde atribut a vrátí jeho obsah - snad nikde jinde není dvojtečka :D\n",
    "            else:\n",
    "                desc.append(value)\n",
    "            if 'Refreshment' in ii:\n",
    "                refresh.append(find_between(ii, 'Refreshment:', ':').rsplit(' ', 1)[0].rsplit(',', 1)[0].strip())\n",
    "            else:\n",
    "                refresh.append(value) \n",
    "            if 'Diving' in ii:\n",
    "                diving.append(find_between(ii, 'Diving:', ':').rsplit(' ', 1)[0].rsplit(',', 1)[0].strip())\n",
    "            else:\n",
    "                diving.append(value)\n",
    "            if 'Accessibility/parking' in ii:\n",
    "                access.append(find_between(ii, 'Accessibility/parking:', ':').rsplit(' ', 1)[0].rsplit(',', 1)[0].strip()) \n",
    "            else:\n",
    "                access.append(value)                                                         \n",
    "            if 'Entrance' in ii:\n",
    "                entrances.append(find_between(ii, 'Entrance:', ':').rsplit(' ', 1)[0].rsplit(',', 1)[0].strip()) \n",
    "            else:\n",
    "                entrances.append(value)\n",
    "            if 'Nudist beach' in ii:\n",
    "                nudists.append(find_between(ii, 'Nudist beach:', ':').rsplit(' ', 1)[0].rsplit(',', 1)[0].strip())\n",
    "            else: \n",
    "                nudists.append(value)\n",
    "        attributes = pd.DataFrame({\n",
    "            'id_a' : ids_att,\n",
    "            'nazev' :nazev,\n",
    "            'Description' : desc,\n",
    "            'Refreshment' : refresh,\n",
    "            'Diving' : diving,\n",
    "            'Entrance' : entrances,\n",
    "            'Accessibility and parking' :access,\n",
    "            'Nudist beach' : nudists\n",
    "        })\n",
    "        return attributes\n",
    "    def mergeData(self):\n",
    "        ''' Merge those 2 data sets, cleaning will follow.'''\n",
    "        output = self.get_data.merge(self.getAtt(), left_on = 'ID', right_on = 'id_a')\n",
    "#         output = output['ids', 'names'] # , 'avg_rating', 'count_ratings', 'created', 'logitude', 'latitude', 'description', 'refreshment', 'diving', 'entrance', 'accessibility_parking', 'nudist_beach']\n",
    "        output.to_csv('raw_data.csv', sep = ',')\n",
    "        return print('Data prepared in csv file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevim, proč se druhý tqdm neukazuje v prubehu - a jak dlouho trva celkove stazeni?\n",
    "- doresit\n",
    "- pridat poznamky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading JSON data from API: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]\n",
      "Searching through the description for attributes:: 100%|██████████| 31/31 [00:00<00:00, 30921.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared in csv file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "swim = Swim()\n",
    "# swim.downloadPages() # update soup - change  -> už není potreba\n",
    "swim.mergeData() - > vytvoreni csv souboru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Average rating</th>\n",
       "      <th>Number of ratings</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>id_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>202936.870968</td>\n",
       "      <td>4.227485</td>\n",
       "      <td>3.741935</td>\n",
       "      <td>49.237986</td>\n",
       "      <td>15.159155</td>\n",
       "      <td>202936.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.092121</td>\n",
       "      <td>27.072424</td>\n",
       "      <td>0.791475</td>\n",
       "      <td>3.010733</td>\n",
       "      <td>1.753516</td>\n",
       "      <td>2.674773</td>\n",
       "      <td>27.072424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>202835.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.760320</td>\n",
       "      <td>2.983775</td>\n",
       "      <td>202835.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>202924.500000</td>\n",
       "      <td>3.964286</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>49.110857</td>\n",
       "      <td>14.339853</td>\n",
       "      <td>202924.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>202944.000000</td>\n",
       "      <td>4.387500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>49.924286</td>\n",
       "      <td>14.942772</td>\n",
       "      <td>202944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>202955.500000</td>\n",
       "      <td>4.892857</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.093087</td>\n",
       "      <td>16.709543</td>\n",
       "      <td>202955.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>202963.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>50.279876</td>\n",
       "      <td>19.445608</td>\n",
       "      <td>202963.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             ID  Average rating  Number of ratings  \\\n",
       "count   31.000000      31.000000       28.000000          31.000000   \n",
       "mean    15.000000  202936.870968        4.227485           3.741935   \n",
       "std      9.092121      27.072424        0.791475           3.010733   \n",
       "min      0.000000  202835.000000        2.000000           0.000000   \n",
       "25%      7.500000  202924.500000        3.964286           1.500000   \n",
       "50%     15.000000  202944.000000        4.387500           3.000000   \n",
       "75%     22.500000  202955.500000        4.892857           5.000000   \n",
       "max     30.000000  202963.000000        5.000000          12.000000   \n",
       "\n",
       "       Longitude   Latitude           id_a  \n",
       "count  31.000000  31.000000      31.000000  \n",
       "mean   49.237986  15.159155  202936.870968  \n",
       "std     1.753516   2.674773      27.072424  \n",
       "min    41.760320   2.983775  202835.000000  \n",
       "25%    49.110857  14.339853  202924.500000  \n",
       "50%    49.924286  14.942772  202944.000000  \n",
       "75%    50.093087  16.709543  202955.500000  \n",
       "max    50.279876  19.445608  202963.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "swim_data = pd.read_csv('raw_data.csv')\n",
    "\n",
    "include = ['object', 'float', 'int']\n",
    "desc = swim_data.describe(include = [np.number]) #providing descriptive statistics, including only numeric columns\n",
    "\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Next steps:__\n",
    "- improve the Class\n",
    "- Clean dataframe & check validity\n",
    "- Analysis of data:\n",
    "    - Descriptive stats\n",
    "    - Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
